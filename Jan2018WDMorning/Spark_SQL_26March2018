1,name,2000,001
2,name2,4000,002
3,name3,5000,005
4,name4,7000,003
5,name5,8000,004
6,name6,8000,004
7,name7,4000,002
8,name8,5000,005

deptdataset
001,hadoop
002,hive
003,pig
005,oozie
006,mapreduce


Working with Data Frames 

1) Create RDDs
2) convert into DF using RDD.toDF
3) apply DF untyped operations.
4) apply SQL on DFs

function -> split line into files and create a tuple

val fn=(line:String)=> {
 val words= line.split(",")
 (words(0),words(1),words(2),words(3))
}

val empRDD=sc.textFile("INPUT/emp").map(fn)

val deptRDD=sc.textFile("INPUT/dept").map(
    line => (line.split(",")(0),line.split(",")(1))
)

val empDF=empRDD.toDF("id","name","sal","deptid")
empDF.printSchema
val deptDF=deptRDD.toDF("id","name")

 empDF.select("id","sal")
.where("sal>5000")
.selectExpr("id","sal","sal+1000").show

SQL on DFs , you need register DF as table ::
empDF.createOrReplaceTempView("t_emp")

spark.sql("select id,sal,sal+1000 as incrsal from t_emp") the result is DF

How to save results into concrete table::
spark.sql("create table res_emp as select id,sal,sal+1000 as incrsal from t_emp")


spark.sql("select id,sal,sal+1000 as incrsal from t_emp")
spark.sql("select * from res_emp")


-------------------------------------------------

Read data using Spark Session:
API -> SaprkSession.read

spark.read.format("csv")
.option("sep",",")
.option("header","true")
.option("inferSchema","true")
.option("mode","DROPMALFORMED")
.load("/home/hadoop/INPUT/emp_header").show

empDF.createOrReplaceTempView("t_empDF")
spark.catalog.listTables.show
spark.sql("create table t_empdf1 as select * from t_empdf")

spark.catalog.listTables.show
+-----------+--------+-----------+---------+-----------+
|       name|database|description|tableType|isTemporary|
+-----------+--------+-----------+---------+-----------+
|        red| default|       null|  MANAGED|      false|
|    res_emp| default|       null|  MANAGED|      false|
|resulttable| default|       null|  MANAGED|      false|
|   t_empdf1| default|       null|  MANAGED|      false|
|       test| default|       null|  MANAGED|      false|
|    t_empdf|    null|       null|TEMPORARY|       true|
+-----------+--------+-----------+---------+-----------+

2533  val jsonDF=spark.read.format("json").option("mode","PERMISSIVE").load("/home/hadoop/INPUT/sample_json.json");
2534  jsonDF.createOrReplaceTempView("jsontable")
2535  jsonDF.printSchema
2536  spark.sql("select name, thumbnail.height,type from jsontable").show

----------------------------------------------
{ "id": "0001", "type": "donut", "name": "Cake", "image":  {   "url":"images/0001.jpg",   "width":200,   "height":200  }, "thumbnail": {   "url": "images/thumbnails/0001.jpg",   "width": 32,   "height": 32  }}
{ "id": "0001", "type": "donut", "name": "Cake", "image":  {   "url":"images/0001.jpg",   "width":200,   "height":200  }, "thumbnail": {   "url": "images/thumbnails/0001.jpg",   "width": 32,   "height": 32  }}
--------------------------------------------
Scala OOP::
how to create class
auxillary constructors
define methods with default values

What is trait?
how to create singleton object
what is companion object -> uses

what is case class?
How to read a file in scala?
Scala lists programming.

-------------------
How to submit spark jobs in production.
------------------
sparkSession.read
DF operations
---------------------
Apache Hive Essentials:
Learning Spark
-----------------------






