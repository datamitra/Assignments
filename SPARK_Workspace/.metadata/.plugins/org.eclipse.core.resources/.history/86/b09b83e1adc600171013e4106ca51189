import org.apache.spark.SparkContext


object WordCount {
  def main(args: Array[String]): Unit = {
    
     //Spark Core::
    val sc = new SparkContext("local[*]", "WordCount")
    val inputRDD=sc.textFile(args(0))
    inputRDD.
    flatMap(line=>line.split(" ")).
    map(word=>(word,1)).
    reduceByKey((x,y)=>x+y).saveAsTextFile(args(1))
  }
 
  
  
}